{"cells":[{"cell_type":"markdown","id":"079b9cbc","metadata":{"id":"079b9cbc"},"source":["# Metaheuristic Optimization for Mixed-Precision Quantization of OPT-1.3B\n","\n","**Prepared by:** Hermela Wosene, Hiwot Teshome, and Melat Dagnachew  \n","**Model:** OPT-1.3B  \n","**Baseline:** AWQ  \n","**Objective:** Minimize perplexity on WikiText-2 using nature-inspired optimization\n","\n","---\n","\n","## Project Scope\n","\n","This notebook implements nature-inspired optimization algorithms to search for per-layer mixed-bit quantization configurations for the OPT-1.3B model. The goal is to identify quantization settings (3-bit or 4-bit) per transformer layer that outperform the AWQ baseline in perplexity, while maintaining efficient inference constraints.\n","\n","We use Differential Evolution (DE) as the first search strategy and evaluate each configuration using AWQâ€™s fake quantization mode. This setup allows rapid, hardware-agnostic performance estimation during optimization.\n"]},{"cell_type":"markdown","source":["## Imports and Constants"],"metadata":{"id":"0ub9tzYas6uU"},"id":"0ub9tzYas6uU"},{"cell_type":"markdown","source":["### 1. Environment Setup and Global Configuration\n","\n","This section defines essential constants such as model path, number of transformer layers, valid quantization bit widths, and output storage locations.\n","\n","The model is assumed to be already downloaded and AWQ installed and patched in a prior notebook (`awq_baseline.ipynb`). This notebook only focuses on quantization search and evaluation.\n"],"metadata":{"id":"DgCwjcHtuCoB"},"id":"DgCwjcHtuCoB"},{"cell_type":"code","execution_count":1,"id":"3fe15cad","metadata":{"id":"3fe15cad","executionInfo":{"status":"ok","timestamp":1769710891862,"user_tz":-180,"elapsed":6,"user":{"displayName":"Hiwot Teshome Lemma","userId":"05255880819904073714"}}},"outputs":[],"source":["import random\n","import numpy as np\n","import subprocess\n","import os\n","import time\n","\n","NUM_LAYERS = 24  # OPT-1.3B\n","BIT_OPTIONS = [3, 4]  # Allowed bit widths\n","AWQ_CACHE = \"/content/drive/MyDrive/LLM_Quant_Project/awq_cache\"\n","MODEL_PATH = \"/content/opt-1.3b\"\n"]},{"cell_type":"markdown","source":["### 2. Layer-wise Quantization Config Generator\n","\n","Each candidate solution is a list of 24 integers (either 3 or 4), representing the weight precision used for each transformer layer. This helper function converts such a list into a format compatible with AWQ.\n","\n","For now, we simulate this by saving a dummy `.pt` file in the format AWQ expects. Later, this can be replaced with actual `run_awq()` outputs if we choose to run real quantization.\n"],"metadata":{"id":"KBTm7O6puKFN"},"id":"KBTm7O6puKFN"},{"cell_type":"markdown","source":["## Convert Layer Vector â†’ AWQ File"],"metadata":{"id":"cClNWWvstFqa"},"id":"cClNWWvstFqa"},{"cell_type":"code","source":["def save_quant_config(bits, out_path):\n","    \"\"\"\n","    Convert list like [4,3,4,...] to AWQ-style .pt config\n","    For now, simulate with dummy AWQ-like placeholder file\n","    \"\"\"\n","    import torch\n","    config = {\n","        \"q_config\": {\n","            \"w_bit\": bits,\n","            \"q_group_size\": [128] * len(bits),\n","            \"zero_point\": True\n","        }\n","    }\n","    torch.save(config, out_path)\n"],"metadata":{"id":"RAivNekStIPI","executionInfo":{"status":"ok","timestamp":1769710894705,"user_tz":-180,"elapsed":2,"user":{"displayName":"Hiwot Teshome Lemma","userId":"05255880819904073714"}}},"id":"RAivNekStIPI","execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["### 3. Evaluation Function\n","\n","This function saves a candidate configuration and evaluates it using the AWQ framework. We invoke the AWQ CLI with `--q_backend fake`, which simulates quantized inference for evaluation purposes without requiring real low-bit kernels.\n","\n","The output perplexity is parsed and returned. If anything fails during evaluation (e.g., timeout or malformed config), a fallback value of infinity is returned to penalize the candidate.\n"],"metadata":{"id":"3eEscn29tNQX"},"id":"3eEscn29tNQX"},{"cell_type":"code","source":["def evaluate_config(bits):\n","    \"\"\"\n","    Save config â†’ run AWQ eval â†’ return perplexity\n","    \"\"\"\n","    config_path = f\"{AWQ_CACHE}/temp_config.pt\"\n","    save_quant_config(bits, config_path)\n","\n","    cmd = [\n","        \"python\", \"-m\", \"awq.entry\",\n","        \"--model_path\", MODEL_PATH,\n","        \"--tasks\", \"wikitext\",\n","        \"--w_bit\", \"4\",\n","        \"--q_group_size\", \"128\",\n","        \"--load_awq\", config_path,\n","        \"--q_backend\", \"fake\"\n","    ]\n","\n","    try:\n","        result = subprocess.run(cmd, capture_output=True, text=True, timeout=180)\n","        output = result.stdout\n","        for line in output.splitlines():\n","            if \"ppl =\" in line:\n","                ppl = float(line.split(\"ppl =\")[-1].strip())\n","                return ppl\n","    except Exception as e:\n","        print(\" Failed to eval:\", e)\n","        return float(\"inf\")\n"],"metadata":{"id":"0itJcUa1tQO9","executionInfo":{"status":"ok","timestamp":1769710899436,"user_tz":-180,"elapsed":19,"user":{"displayName":"Hiwot Teshome Lemma","userId":"05255880819904073714"}}},"id":"0itJcUa1tQO9","execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### 4. Metaheuristic Optimization: Differential Evolution (DE)\n","\n","We implement a simple version of DE with random mutation between population members. Each candidate is evaluated based on perplexity, and the best configuration is preserved across generations.\n","\n","This algorithm allows exploration of the discrete search space (3/4-bit decisions) without needing gradients or internal model knowledge.\n"],"metadata":{"id":"b0bFdPk9tYG0"},"id":"b0bFdPk9tYG0"},{"cell_type":"code","source":["def random_candidate():\n","    return [random.choice(BIT_OPTIONS) for _ in range(NUM_LAYERS)]\n","\n","def mutate(target, donor, F=0.5):\n","    return [random.choice([t, d]) for t, d in zip(target, donor)]\n","\n","def differential_evolution(pop_size=6, generations=5):\n","    pop = [random_candidate() for _ in range(pop_size)]\n","    scores = [evaluate_config(p) for p in pop]\n","\n","    for g in range(generations):\n","        print(f\"\\n Generation {g}\")\n","        for i in range(pop_size):\n","            x = pop[i]\n","            a, b = random.sample([p for j, p in enumerate(pop) if j != i], 2)\n","            trial = mutate(a, b)\n","            trial_score = evaluate_config(trial)\n","\n","            if trial_score < scores[i]:\n","                pop[i], scores[i] = trial, trial_score\n","                print(f\"  âœ” New best for individual {i}: {trial_score:.3f}\")\n","\n","    best_idx = np.argmin(scores)\n","    return pop[best_idx], scores[best_idx]\n"],"metadata":{"id":"D_Mgp9KatdkO","executionInfo":{"status":"ok","timestamp":1769710903090,"user_tz":-180,"elapsed":21,"user":{"displayName":"Hiwot Teshome Lemma","userId":"05255880819904073714"}}},"id":"D_Mgp9KatdkO","execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# Section 5: Particle Swarm Optimization\n","# Swarm algorithm using discrete bit flipping in velocity updates"],"metadata":{"id":"CJiZpaiMxClg"},"id":"CJiZpaiMxClg"},{"cell_type":"code","source":["def run_pso(swarm_size=6, iterations=5):\n","  swarm = [random_candidate() for _ in range(swarm_size)]\n","  velocities = [random_candidate() for _ in range(swarm_size)]\n","  personal_best = swarm[:]\n","  p_scores = [evaluate_config(p) for p in swarm]\n","  global_best = personal_best[np.argmin(p_scores)]\n","\n","  for t in range(iterations):\n","    print(f\"\\n Iteration {t}\")\n","  for i in range(swarm_size):\n","    candidate = []\n","  for j in range(NUM_LAYERS):\n","    flip = random.random() < 0.5\n","    candidate.append(global_best[j] if flip else swarm[i][j])\n","    score = evaluate_config(candidate)\n","  if score < p_scores[i]:\n","    personal_best[i], p_scores[i] = candidate, score\n","    print(f\" Particle {i} improved: PPL = {score:.3f}\")\n","    global_best = personal_best[np.argmin(p_scores)]\n","\n","  return global_best, min(p_scores)\n","\n","\n"],"metadata":{"id":"vCLu_8u0xGot","executionInfo":{"status":"ok","timestamp":1769711020139,"user_tz":-180,"elapsed":11,"user":{"displayName":"Hiwot Teshome Lemma","userId":"05255880819904073714"}}},"id":"vCLu_8u0xGot","execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# Section 6: Simulated Annealing\n","# Physics-inspired stochastic hill-climber with temperature schedule"],"metadata":{"id":"aXmR12cMxJNU"},"id":"aXmR12cMxJNU"},{"cell_type":"code","source":["def run_sa(iters=25, temp=1.0, cooling=0.9):\n","    current = random_candidate()\n","    current_score = evaluate_config(current)\n","\n","\n","    for i in range(iters):\n","        neighbor = current[:]\n","        idx = random.randint(0, NUM_LAYERS - 1)\n","        neighbor[idx] = 3 if current[idx] == 4 else 4\n","        new_score = evaluate_config(neighbor)\n","\n","\n","        if new_score < current_score or random.random() < np.exp((current_score - new_score) / temp):\n","            current, current_score = neighbor, new_score\n","            print(f\" Accepted new config at T={temp:.3f}, PPL={new_score:.3f}\")\n","        temp *= cooling\n","\n","\n","    return current, current_score"],"metadata":{"id":"BbLbjMtjxKbp","executionInfo":{"status":"ok","timestamp":1769711218335,"user_tz":-180,"elapsed":608,"user":{"displayName":"Hiwot Teshome Lemma","userId":"05255880819904073714"}}},"id":"BbLbjMtjxKbp","execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# Section 7: Algorithm Selector + Logging\n","# Choose which algorithm to run, log best result to CSV"],"metadata":{"id":"1opa-bFCxRqs"},"id":"1opa-bFCxRqs"},{"cell_type":"code","source":["RUN_ALGO = \"de\" # Change to \"pso\" or \"sa\" to run others\n","\n","\n","if RUN_ALGO == \"de\":\n","    # Note: `run_de` function is not defined in the provided notebook state.\n","    # Assuming `differential_evolution` should be called here based on context.\n","    # Or `run_de` is a placeholder for a function that will be defined later.\n","    # For now, I'll use `differential_evolution` as it's defined and imported.\n","    best_cfg, best_ppl = differential_evolution()\n","elif RUN_ALGO == \"pso\":\n","    best_cfg, best_ppl = run_pso()\n","elif RUN_ALGO == \"sa\":\n","    best_cfg, best_ppl = run_sa()\n","\n","\n","print(\"\\nðŸ† Best PPL:\", best_ppl)\n","print(\"ðŸ§  Best Config:\", best_cfg)\n","\n","# Note: RESULTS_PATH is not defined in the provided notebook state.\n","# Assuming `results_path` from the last cell (LY7zPyp5tlx7) should be used.\n","results_path = \"/content/drive/MyDrive/LLM_Quant_Project/results.csv\"\n","import csv # Importing csv module as it's used later\n","\n","row = [\"OPT-1.3B\", RUN_ALGO.upper(), \"3/4-mixed\", \"128\", \"64\", best_ppl]\n","with open(results_path, \"a\", newline=\"\") as f:\n","    csv.writer(f).writerow(row)\n","print(\" Result saved to CSV.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"egG_zVn5xQw1","executionInfo":{"status":"error","timestamp":1769711249438,"user_tz":-180,"elapsed":3070,"user":{"displayName":"Hiwot Teshome Lemma","userId":"05255880819904073714"}},"outputId":"0a3096d2-8519-477d-a021-6496d225668d"},"id":"egG_zVn5xQw1","execution_count":11,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Parent directory /content/drive/MyDrive/LLM_Quant_Project/awq_cache does not exist.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1454929956.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Or `run_de` is a placeholder for a function that will be defined later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# For now, I'll use `differential_evolution` as it's defined and imported.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mbest_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_ppl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdifferential_evolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mRUN_ALGO\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pso\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mbest_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_ppl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_pso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-3170399783.py\u001b[0m in \u001b[0;36mdifferential_evolution\u001b[0;34m(pop_size, generations)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdifferential_evolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpop_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrandom_candidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpop_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mevaluate_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-265283885.py\u001b[0m in \u001b[0;36mevaluate_config\u001b[0;34m(bits)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m      5\u001b[0m     \u001b[0mconfig_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{AWQ_CACHE}/temp_config.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msave_quant_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     cmd = [\n","\u001b[0;32m/tmp/ipython-input-1617198382.py\u001b[0m in \u001b[0;36msave_quant_config\u001b[0;34m(bits, out_path)\u001b[0m\n\u001b[1;32m     12\u001b[0m         }\n\u001b[1;32m     13\u001b[0m     }\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m             _save(\n\u001b[1;32m    968\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0mcontainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_zipfile_writer_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             super().__init__(\n\u001b[0;32m--> 792\u001b[0;31m                 torch._C.PyTorchFileWriter(\n\u001b[0m\u001b[1;32m    793\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_crc32_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_get_storage_alignment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                 )\n","\u001b[0;31mRuntimeError\u001b[0m: Parent directory /content/drive/MyDrive/LLM_Quant_Project/awq_cache does not exist."]}]},{"cell_type":"markdown","source":["## Run Opitmization and save best"],"metadata":{"id":"K6AaTH4JtgTb"},"id":"K6AaTH4JtgTb"},{"cell_type":"code","source":["best_config, best_score = differential_evolution(pop_size=6, generations=3)\n","print(\" Best perplexity:\", best_score)\n","print(\" Best bit config:\", best_config)\n","\n","# Save to results file\n","import csv\n","\n","results_path = \"/content/drive/MyDrive/LLM_Quant_Project/results.csv\"\n","row = [\"OPT-1.3B\", \"DE\", \"3/4-mixed\", \"128\", \"64\", best_score]\n","\n","with open(results_path, \"a\", newline=\"\") as f:\n","    csv.writer(f).writerow(row)\n"],"metadata":{"id":"LY7zPyp5tlx7"},"id":"LY7zPyp5tlx7","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":".venv (3.10.11)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}